{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b6e98b",
   "metadata": {},
   "source": [
    "#### Creating the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde007ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1115394/1115394 [==============================] - 2s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1005ea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2d6e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\", standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ecb6d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded -= 2 # drop tokens 0 (pad) and 1 (unknown), which we will not use\n",
    "n_tokens = text_vec_layer.vocabulary_size()-2\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c2d586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = len(encoded)\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf50d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "        \n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "087ee289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 4,  5,  2, 23]], dtype=int64)>,\n",
       "  <tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[ 5,  2, 23,  3]], dtype=int64)>)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(to_dataset(text_vec_layer([\"To be\"])[0], length=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10f90b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100 # window length\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ba5d6",
   "metadata": {},
   "source": [
    "#### Building and Training the Char-RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "102e5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dded8dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31247/31247 [==============================] - 2391s 76ms/step - loss: 1.3926 - accuracy: 0.5744 - val_loss: 1.6078 - val_accuracy: 0.5357\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 2991s 95ms/step - loss: 1.2935 - accuracy: 0.5974 - val_loss: 1.5845 - val_accuracy: 0.5396\n",
      "Epoch 3/10\n",
      "31247/31247 [==============================] - 2924s 93ms/step - loss: 1.2747 - accuracy: 0.6015 - val_loss: 1.5732 - val_accuracy: 0.5440\n",
      "Epoch 4/10\n",
      "31247/31247 [==============================] - 2891s 92ms/step - loss: 1.2657 - accuracy: 0.6036 - val_loss: 1.5677 - val_accuracy: 0.5448\n",
      "Epoch 5/10\n",
      "31247/31247 [==============================] - 2896s 92ms/step - loss: 1.2588 - accuracy: 0.6051 - val_loss: 1.5621 - val_accuracy: 0.5444\n",
      "Epoch 6/10\n",
      "31247/31247 [==============================] - 2902s 92ms/step - loss: 1.2550 - accuracy: 0.6059 - val_loss: 1.5571 - val_accuracy: 0.5470\n",
      "Epoch 7/10\n",
      "31247/31247 [==============================] - 2863s 91ms/step - loss: 1.2510 - accuracy: 0.6067 - val_loss: 1.5485 - val_accuracy: 0.5495\n",
      "Epoch 8/10\n",
      "31247/31247 [==============================] - 2857s 91ms/step - loss: 1.2481 - accuracy: 0.6074 - val_loss: 1.5492 - val_accuracy: 0.5509\n",
      "Epoch 9/10\n",
      "31247/31247 [==============================] - 2846s 90ms/step - loss: 1.2459 - accuracy: 0.6079 - val_loss: 1.5455 - val_accuracy: 0.5502\n",
      "Epoch 10/10\n",
      "31247/31247 [==============================] - 2849s 91ms/step - loss: 1.2439 - accuracy: 0.6083 - val_loss: 1.5500 - val_accuracy: 0.5509\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model.h5\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10, callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba4f69",
   "metadata": {},
   "source": [
    "This model does not hnadle text preprocessing, let's wrap it in a final a model containing `tf.keras.layers.TextVectorization` layer as the first layer and a `tf.keras.layers.Lambda` layer to subtract 2 from the character IDs since we are not using  the padding and unknown tokens for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc638378",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X:X-2), # no <PAD> or <UNKNOWN> tokens\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f2e0705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 574ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Next Character\n",
    "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0,-1]\n",
    "y_pred = tf.argmax(y_proba)\n",
    "\n",
    "text_vec_layer.get_vocabulary()[y_pred+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d0dea",
   "metadata": {},
   "source": [
    "#### Generating Fake Shakespearean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bec51d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 1, 0, 2, 1, 0, 0, 1]], dtype=int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])\n",
    "tf.random.set_seed(42)\n",
    "tf.random.categorical(log_probas, num_samples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d70c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
    "    rescaled_logits = tf.math.log(y_proba)/temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0,0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb6ebf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dea92b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "To be or not to be a shame.\n",
      "\n",
      "provost:\n",
      "i will be so the duke of sorro\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(extend_text(\"To be or not to be\", temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38646502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "To be or not to be noble an altly,\n",
      "every profession in nothing; most\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(extend_text(\"To be or not to be\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2c4acf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "To be or not to belfzzy.cik pua!&j. :bhfr3'db\n",
      "t,bzhbp.rkp,qzz!$ badp\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(extend_text(\"To be or not to be\", temperature=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb473ec",
   "metadata": {},
   "source": [
    "#### Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c3c2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset_for_stateful_rnn(sequence, length):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89f83960",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length=length)\n",
    "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length=length)\n",
    "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb9cd7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateful_rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16, batch_input_shape=[1, None]),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e59e96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1bc48363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9999/9999 [==============================] - 376s 37ms/step - loss: 1.8725 - accuracy: 0.4493 - val_loss: 1.7127 - val_accuracy: 0.4866\n",
      "Epoch 2/10\n",
      "9999/9999 [==============================] - 374s 37ms/step - loss: 1.5643 - accuracy: 0.5280 - val_loss: 1.6243 - val_accuracy: 0.5138\n",
      "Epoch 3/10\n",
      "9999/9999 [==============================] - 371s 37ms/step - loss: 1.4870 - accuracy: 0.5477 - val_loss: 1.5849 - val_accuracy: 0.5262\n",
      "Epoch 4/10\n",
      "9999/9999 [==============================] - 367s 37ms/step - loss: 1.4479 - accuracy: 0.5578 - val_loss: 1.5609 - val_accuracy: 0.5323\n",
      "Epoch 5/10\n",
      "9999/9999 [==============================] - 363s 36ms/step - loss: 1.4235 - accuracy: 0.5641 - val_loss: 1.5439 - val_accuracy: 0.5366\n",
      "Epoch 6/10\n",
      "9999/9999 [==============================] - 364s 36ms/step - loss: 1.4069 - accuracy: 0.5684 - val_loss: 1.5359 - val_accuracy: 0.5383\n",
      "Epoch 7/10\n",
      "9999/9999 [==============================] - 365s 36ms/step - loss: 1.3950 - accuracy: 0.5714 - val_loss: 1.5322 - val_accuracy: 0.5400\n",
      "Epoch 8/10\n",
      "9999/9999 [==============================] - 369s 37ms/step - loss: 1.3862 - accuracy: 0.5737 - val_loss: 1.5279 - val_accuracy: 0.5411\n",
      "Epoch 9/10\n",
      "9999/9999 [==============================] - 368s 37ms/step - loss: 1.3794 - accuracy: 0.5752 - val_loss: 1.5260 - val_accuracy: 0.5413\n",
      "Epoch 10/10\n",
      "9999/9999 [==============================] - 370s 37ms/step - loss: 1.3739 - accuracy: 0.5767 - val_loss: 1.5240 - val_accuracy: 0.5413\n"
     ]
    }
   ],
   "source": [
    "stateful_rnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = stateful_rnn_model.fit(stateful_train_set, validation_data=stateful_valid_set,\n",
    "                    epochs=10, callbacks=[ResetStatesCallback(), model_ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693f81db",
   "metadata": {},
   "source": [
    "### Converting the stateful RNN to a stateless RNN and using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6fdae1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beef805",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None]))\n",
    "stateless_model.set_weights(st.get_weights())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
