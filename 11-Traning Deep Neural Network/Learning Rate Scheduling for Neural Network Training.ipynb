{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acfa16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = mnist\n",
    "\n",
    "X_train, X_test = X_train/255. , X_test/255.\n",
    "\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78764de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199210 (778.16 KB)\n",
      "Trainable params: 199210 (778.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022a414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.6689 - accuracy: 0.8315 - val_loss: 0.2886 - val_accuracy: 0.9228\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.3040 - accuracy: 0.9137 - val_loss: 0.2246 - val_accuracy: 0.9355\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2516 - accuracy: 0.9268 - val_loss: 0.1912 - val_accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer = optimizer,\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fd080",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c739ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.2173 - accuracy: 0.9375 - val_loss: 0.1670 - val_accuracy: 0.9542\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1920 - accuracy: 0.9447 - val_loss: 0.1509 - val_accuracy: 0.9587\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1712 - accuracy: 0.9507 - val_loss: 0.1388 - val_accuracy: 0.9612\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, weight_decay=0.0001)\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer = optimizer,\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7029dc",
   "metadata": {},
   "source": [
    "### Exponential Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194f9ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1541 - accuracy: 0.9557 - val_loss: 0.1281 - val_accuracy: 0.9668 - lr: 0.0100\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1394 - accuracy: 0.9602 - val_loss: 0.1200 - val_accuracy: 0.9685 - lr: 0.0089\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1284 - accuracy: 0.9637 - val_loss: 0.1133 - val_accuracy: 0.9685 - lr: 0.0079\n"
     ]
    }
   ],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1 ** (epoch / 20)\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=initial_learning_rate)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: exponential_decay_fn(epoch, initial_learning_rate)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, validation_split=0.1, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b39513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.008912509, 0.007943282]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learing rate schedules\n",
    "history.history[\"lr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fad568",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f0ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0528 - accuracy: 0.9858 - val_loss: 0.0762 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0500 - accuracy: 0.9865 - val_loss: 0.0788 - val_accuracy: 0.9787 - lr: 0.0100\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0472 - accuracy: 0.9876 - val_loss: 0.0788 - val_accuracy: 0.9785 - lr: 0.0100\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0431 - accuracy: 0.9891 - val_loss: 0.0741 - val_accuracy: 0.9800 - lr: 0.0050\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0415 - accuracy: 0.9897 - val_loss: 0.0729 - val_accuracy: 0.9808 - lr: 0.0050\n"
     ]
    }
   ],
   "source": [
    "def piecewise_constant_lr_fn(epoch):\n",
    "    if epoch<3:\n",
    "        return 0.01\n",
    "    elif epoch<15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "    \n",
    "    \n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: piecewise_constant_lr_fn(epoch)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_split=0.1, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a6024e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.01, 0.01, 0.005, 0.005]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"lr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b92ab",
   "metadata": {},
   "source": [
    "### Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cad94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0421 - accuracy: 0.9894 - val_loss: 0.0750 - val_accuracy: 0.9795\n",
      "Epoch 2/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0397 - accuracy: 0.9902 - val_loss: 0.0726 - val_accuracy: 0.9807\n",
      "Epoch 3/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0374 - accuracy: 0.9913 - val_loss: 0.0730 - val_accuracy: 0.9803\n",
      "Epoch 4/15\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0358 - accuracy: 0.9915 - val_loss: 0.0720 - val_accuracy: 0.9795\n",
      "Epoch 5/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0342 - accuracy: 0.9922 - val_loss: 0.0719 - val_accuracy: 0.9800\n",
      "Epoch 6/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0331 - accuracy: 0.9926 - val_loss: 0.0713 - val_accuracy: 0.9805\n",
      "Epoch 7/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0322 - accuracy: 0.9932 - val_loss: 0.0721 - val_accuracy: 0.9813\n",
      "Epoch 8/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0312 - accuracy: 0.9931 - val_loss: 0.0726 - val_accuracy: 0.9808\n",
      "Epoch 9/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 0.0724 - val_accuracy: 0.9805\n",
      "Epoch 10/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0299 - accuracy: 0.9938 - val_loss: 0.0720 - val_accuracy: 0.9808\n",
      "Epoch 11/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0294 - accuracy: 0.9938 - val_loss: 0.0716 - val_accuracy: 0.9812\n",
      "Epoch 12/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0289 - accuracy: 0.9941 - val_loss: 0.0712 - val_accuracy: 0.9818\n",
      "Epoch 13/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0284 - accuracy: 0.9942 - val_loss: 0.0712 - val_accuracy: 0.9815\n",
      "Epoch 14/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0281 - accuracy: 0.9942 - val_loss: 0.0711 - val_accuracy: 0.9812\n",
      "Epoch 15/15\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0279 - accuracy: 0.9944 - val_loss: 0.0709 - val_accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 15\n",
    "n_steps = n_epochs * math.ceil(len(X_train)/batch_size)\n",
    "\n",
    "schedule_learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=n_steps, decay_rate=0.1\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=schedule_learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=15, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213051c",
   "metadata": {},
   "source": [
    "Performance Scheduling is consideded one of the best learning rate schedulin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
